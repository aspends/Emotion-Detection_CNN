{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from keras.metrics import Precision, Recall\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"archive-7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(dir):\n",
    "    image_location = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        label_path = os.path.join(dir, label)\n",
    "        if os.path.isdir(label_path):\n",
    "            labels.extend([label] * len(os.listdir(label_path)))\n",
    "            for image in os.listdir(label_path):\n",
    "                image_location.append(os.path.join(label_path, image))\n",
    "            print(label, \"completed\")\n",
    "        else:\n",
    "            print(f\"{label} is not a folder, skipping...\")\n",
    "    return image_location, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.csv is not a folder, skipping...\n",
      "happy completed\n",
      "contempt completed\n",
      "sad completed\n",
      "fear completed\n",
      "surprise completed\n",
      "neutral completed\n",
      "anger completed\n",
      "disgust completed\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "data['image'], data['label'] = create_dataframe(image_dir)\n",
    "data.to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image, grayscale=True)\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features), 48, 48, 1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a4e64126f34af89074320b1f6513bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b0c25c229e42f2a9c949f6427c2879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_features = extract_features(train['image'])\n",
    "validation_features = extract_features(validation['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features /225.0\n",
    "x_val = validation_features / 225.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(train['label'])\n",
    "y_train = label_encoder.transform(train['label'])\n",
    "y_val = label_encoder.transform(validation['label'])\n",
    "y_train = to_categorical(y_train, num_classes=7)\n",
    "y_val = to_categorical(y_val, num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_16 (Conv2D)          (None, 46, 46, 128)       1280      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPooli  (None, 23, 23, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 23, 23, 128)       0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 21, 21, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPooli  (None, 10, 10, 256)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 10, 10, 256)       0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 8, 8, 512)         1180160   \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPooli  (None, 4, 4, 512)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPooli  (None, 1, 1, 512)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4232199 (16.14 MB)\n",
      "Trainable params: 4232199 (16.14 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# convolutional layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "# fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.summary()\n",
    "# model compilation\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy', Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-17 21:32:27.168635: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/226 [==============================] - ETA: 0s - loss: 1.8341 - accuracy: 0.2377 - precision_2: 0.2424 - recall_2: 0.0011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-17 21:33:22.375233: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/226 [==============================] - 59s 245ms/step - loss: 1.8341 - accuracy: 0.2377 - precision_2: 0.2424 - recall_2: 0.0011 - val_loss: 1.8139 - val_accuracy: 0.2583 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 2/100\n",
      "226/226 [==============================] - 62s 273ms/step - loss: 1.8120 - accuracy: 0.2482 - precision_2: 0.2683 - recall_2: 3.8167e-04 - val_loss: 1.7957 - val_accuracy: 0.2654 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 3/100\n",
      "226/226 [==============================] - 56s 248ms/step - loss: 1.7810 - accuracy: 0.2632 - precision_2: 0.5169 - recall_2: 0.0096 - val_loss: 1.6871 - val_accuracy: 0.3140 - val_precision_2: 0.7644 - val_recall_2: 0.0243\n",
      "Epoch 4/100\n",
      "226/226 [==============================] - 74s 325ms/step - loss: 1.7760 - accuracy: 0.3015 - precision_2: 0.4965 - recall_2: 0.0680 - val_loss: 1.7522 - val_accuracy: 0.3191 - val_precision_2: 0.5571 - val_recall_2: 0.0401\n",
      "Epoch 5/100\n",
      "226/226 [==============================] - 60s 265ms/step - loss: 1.8987 - accuracy: 0.3118 - precision_2: 0.4493 - recall_2: 0.1349 - val_loss: 1.9777 - val_accuracy: 0.2867 - val_precision_2: 0.3192 - val_recall_2: 0.1224\n",
      "Epoch 6/100\n",
      "226/226 [==============================] - 59s 259ms/step - loss: 2.7052 - accuracy: 0.2892 - precision_2: 0.3305 - recall_2: 0.1914 - val_loss: 2.9758 - val_accuracy: 0.2502 - val_precision_2: 0.2811 - val_recall_2: 0.1608\n",
      "Epoch 7/100\n",
      "226/226 [==============================] - 61s 268ms/step - loss: 4.8378 - accuracy: 0.2733 - precision_2: 0.2874 - recall_2: 0.2330 - val_loss: 5.2031 - val_accuracy: 0.3210 - val_precision_2: 0.3284 - val_recall_2: 0.3130\n",
      "Epoch 8/100\n",
      "226/226 [==============================] - 58s 254ms/step - loss: 10.3081 - accuracy: 0.2178 - precision_2: 0.2239 - recall_2: 0.1862 - val_loss: 11.6937 - val_accuracy: 0.2590 - val_precision_2: 0.2591 - val_recall_2: 0.2567\n",
      "Epoch 9/100\n",
      "226/226 [==============================] - 57s 251ms/step - loss: 20.1204 - accuracy: 0.2393 - precision_2: 0.2416 - recall_2: 0.2341 - val_loss: 9.4387 - val_accuracy: 0.1619 - val_precision_2: 0.1619 - val_recall_2: 0.1619\n",
      "Epoch 10/100\n",
      "226/226 [==============================] - 55s 245ms/step - loss: 38.1320 - accuracy: 0.2378 - precision_2: 0.2383 - recall_2: 0.2355 - val_loss: 28.5821 - val_accuracy: 0.2935 - val_precision_2: 0.2941 - val_recall_2: 0.2931\n",
      "Epoch 11/100\n",
      "226/226 [==============================] - 55s 245ms/step - loss: 44.9157 - accuracy: 0.2564 - precision_2: 0.2566 - recall_2: 0.2557 - val_loss: 61.6827 - val_accuracy: 0.2563 - val_precision_2: 0.2562 - val_recall_2: 0.2562\n",
      "Epoch 12/100\n",
      "226/226 [==============================] - 54s 241ms/step - loss: 291.3350 - accuracy: 0.2153 - precision_2: 0.2153 - recall_2: 0.2153 - val_loss: 212.4220 - val_accuracy: 0.0378 - val_precision_2: 0.0378 - val_recall_2: 0.0378\n",
      "Epoch 13/100\n",
      "226/226 [==============================] - 54s 240ms/step - loss: 213.1207 - accuracy: 0.2529 - precision_2: 0.2529 - recall_2: 0.2528 - val_loss: 217.5641 - val_accuracy: 0.2414 - val_precision_2: 0.2414 - val_recall_2: 0.2414\n",
      "Epoch 14/100\n",
      "226/226 [==============================] - 55s 242ms/step - loss: 504.5531 - accuracy: 0.2610 - precision_2: 0.2610 - recall_2: 0.2610 - val_loss: 699.3036 - val_accuracy: 0.3414 - val_precision_2: 0.3414 - val_recall_2: 0.3414\n",
      "Epoch 15/100\n",
      "226/226 [==============================] - 53s 234ms/step - loss: 1516.9961 - accuracy: 0.2579 - precision_2: 0.2579 - recall_2: 0.2579 - val_loss: 1819.8854 - val_accuracy: 0.2487 - val_precision_2: 0.2487 - val_recall_2: 0.2487\n",
      "Epoch 16/100\n",
      "226/226 [==============================] - 54s 240ms/step - loss: 2078.8621 - accuracy: 0.2722 - precision_2: 0.2722 - recall_2: 0.2722 - val_loss: 1841.5746 - val_accuracy: 0.2785 - val_precision_2: 0.2785 - val_recall_2: 0.2785\n",
      "Epoch 17/100\n",
      "226/226 [==============================] - 56s 250ms/step - loss: 2075.9460 - accuracy: 0.2849 - precision_2: 0.2849 - recall_2: 0.2849 - val_loss: 2154.7097 - val_accuracy: 0.2629 - val_precision_2: 0.2629 - val_recall_2: 0.2629\n",
      "Epoch 18/100\n",
      "226/226 [==============================] - 60s 263ms/step - loss: 2267.0913 - accuracy: 0.2843 - precision_2: 0.2843 - recall_2: 0.2843 - val_loss: 2334.6860 - val_accuracy: 0.2550 - val_precision_2: 0.2550 - val_recall_2: 0.2550\n",
      "Epoch 19/100\n",
      "226/226 [==============================] - 58s 247ms/step - loss: 2875.2219 - accuracy: 0.2906 - precision_2: 0.2906 - recall_2: 0.2906 - val_loss: 5962.9980 - val_accuracy: 0.2532 - val_precision_2: 0.2532 - val_recall_2: 0.2532\n",
      "Epoch 20/100\n",
      "226/226 [==============================] - 59s 261ms/step - loss: 5025.0205 - accuracy: 0.2755 - precision_2: 0.2755 - recall_2: 0.2755 - val_loss: 3340.6448 - val_accuracy: 0.3564 - val_precision_2: 0.3564 - val_recall_2: 0.3564\n",
      "Epoch 21/100\n",
      " 80/226 [=========>....................] - ETA: 34s - loss: 4082.9707 - accuracy: 0.2811 - precision_2: 0.2811 - recall_2: 0.2811"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=x_train,\n",
    "          y=y_train,\n",
    "          batch_size=128,\n",
    "          epochs=100,\n",
    "          validation_data=(x_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "acc = history_dict['accuracy']\n",
    "loss = history_dict['loss']\n",
    "precision = history_dict['precision']\n",
    "recall = history_dict['recall']\n",
    "val_acc = history.history.get('val_accuracy')\n",
    "val_loss = history.history.get('val_loss')\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, val_acc)\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['Accuracy', 'Val. Accuracy'])\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(epochs,loss)\n",
    "plt.plot(epochs,val_loss)\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['Loss', 'Val. Loss'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
